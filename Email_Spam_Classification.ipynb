{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email_Spam_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blessingsMlundira/indabaX_lab/blob/main/Email_Spam_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6XLKWV77EaU"
      },
      "source": [
        "**INTRODUCTION TO ML: SUPPORT VECTOR MACHINES**\n",
        "\n",
        "In this session, we implement and train a support vector machine (SVM in short) for text classification.\n",
        "Support Vector Machine (SVM) is a supervised machine learning algorithm which can be used for both classification or regression challenges. However, it is mostly used in classification problems.\n",
        "\n",
        "**LEARNING OBJECTIVES** \n",
        "\n",
        "*   Understand how to use sklearn and pandas libraries to build a text classifier\n",
        "*   Understand how a text classification model is trained and evaluated\n",
        "*   Improving model performance\n",
        "*   Applications of text classification algorithms(email spam classification).\n",
        "\n",
        "\n",
        "\n",
        "**EMAIL SPAM CLASSIFICATION**\n",
        "\n",
        "Email spam, also referred to as junk email or simply SPAM, is unsolicited messages sent in bulk by email (spamming). \n",
        "\n",
        "Most email spam messages are commercial in nature. Whether commercial or not, many are not only annoying, but also dangerous because they may contain links that lead to phishing web sites or sites that are hosting malware or include malware as file attachments.\n",
        "\n",
        "Spammers collect email addresses from chat rooms, websites, customer lists, newsgroups, and viruses that harvest users' address books. These collected email addresses are sometimes also sold to other spammers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTJ86cdz8yDa"
      },
      "source": [
        "In this session we are going to use scikit-learn to classify emails as spam or not. Scikit-learn is part of the Python machine learning toolkit at JPMorgan. It is very widely used for classification, predictive analytics, and many other machine learning tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTR3Tybp5HNh"
      },
      "source": [
        "#make sure you have all the necessary libraries installed\n",
        "#then make sure you download the dataset.\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn import svm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TFwHg_H-H03"
      },
      "source": [
        "Lets build our csv file, and we will use the pandas library to do that.\n",
        "The type of object that the pandas returns is called a dataframe so we will be calling our variable dataframe aswell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwdlWaWQI085",
        "outputId": "45b9e40f-5dcc-4a7d-b006-31ac30fe65fe"
      },
      "source": [
        "#lets mount our drive to get access to the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWOYXDs5-ZsN"
      },
      "source": [
        "#Load Dataset\n",
        "url = \"https://raw.githubusercontent.com/blessingsMlundira/logistic_regression/main/spam.csv\"\n",
        "dataframe = pd.read_csv(url)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpyM3zFR-nYZ"
      },
      "source": [
        "**Lets see what is inside our dataframe now**\n",
        "\n",
        "You can print the entire dataset or just view parts of it using the head() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs4DY4ZC-1UP",
        "outputId": "eab2dad7-812b-4c2e-984d-d3f31e7fd0c8"
      },
      "source": [
        "print(dataframe.head()) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Label                                          EmailText\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td2VTJjq-8Kx"
      },
      "source": [
        "We can also use the describe() function to get some statistical properties of our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3_Ynplv_Czi",
        "outputId": "e3a486a5-d0ed-40cd-9ebd-8610dcc1ea5d"
      },
      "source": [
        "print(dataframe.describe())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Label               EmailText\n",
            "count   5572                    5572\n",
            "unique     2                    5169\n",
            "top      ham  Sorry, I'll call later\n",
            "freq    4825                      30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bEHHnIH_MEv"
      },
      "source": [
        "When we are building out machine learning models we are also interested in finding out how well our model is performing, so we want to evaluate our model aswell so instead of using the entire dataset for training, we split the data into training set and test dataset. The goal here is to use 80% of our data as the training set and 20% as the testset for our testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi_0z_2q_k7u"
      },
      "source": [
        "Lets now separate our training set and our test dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfqOTPGU_Xvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c0c61c-ebc6-493e-df9e-03ee339173df"
      },
      "source": [
        "#Split in to Training and Test Data\n",
        "\n",
        "# we will separate our columns\n",
        "\n",
        "x = dataframe[\"EmailText\"]\n",
        "y = dataframe[\"Label\"]\n",
        "\n",
        "# we will also separete x train and y train and similary x test and y test\n",
        "# there are other ways to split our data, you could use some methods from sklearn\n",
        "# initially size_train=4457\n",
        "\n",
        "\n",
        "size_train=input(\"Enter size train : \")\n",
        "x_train,y_train = x[0:int(size_train)],y[0:int(size_train)]\n",
        "x_test,y_test = x[int(size_train):],y[int(size_train):]\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter size train : 400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeOg6Uib_9lC"
      },
      "source": [
        "The next step is to extract features, note that in our x train we have strings, and in machine learning we will use statistical models since they numbers to work.\n",
        "\n",
        "How do we represent these strings as numbers? \n",
        "***one way we can do this is by presenting the count of words which appear in each of these strings***\n",
        "For example if we have \"London Paris London\" London will be represented as 2 and Paris as 1.\n",
        "\n",
        "This also happens to be a common operation when we are dealing with text data for machine learning so sklearn provides us with a class called count **CountVectorizer** to represent our string thus count of words that are occuring.\n",
        "\n",
        "We can use fit and transform on a collection of strings and then it will give us a count of words. Lets go ahead and use it in our program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "351iGJw7A3Bg"
      },
      "source": [
        "#Extract Features\n",
        "cv = CountVectorizer()  \n",
        "features = cv.fit_transform(x_train)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0-7--_JBC38"
      },
      "source": [
        "Now we have our features extracted and we are now ready to build a model. We will use a support vector machine as a classifier because it performs well on problems that have too many features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmMZKShMBLUa",
        "outputId": "5a990d64-cb3a-4ff8-eb2e-794ba6e12bcc"
      },
      "source": [
        "model = svm.SVC()\n",
        "model.fit(features,y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwdiCJfeBRlD"
      },
      "source": [
        "Then we will now test the performance, but before we evaluate we must also convert our x_test to features just like we did during the training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j16yV8b0BcSq"
      },
      "source": [
        "features_test = cv.transform(x_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIUJyEPxBgrj"
      },
      "source": [
        "Next lets how the model performs using the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi9Ny_vHBmrn",
        "outputId": "fbe42898-8ea1-4d02-c4d1-40aeb4a33881"
      },
      "source": [
        "\n",
        "print(\"accuracy of the model : \",model.score(features_test,y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the model :  0.9216937354988399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivX6X3fkuZPs",
        "outputId": "132dbe6b-6dcc-4621-e1fa-01cd7a1441b4"
      },
      "source": [
        "# df = pd.DataFrame({\"predicted \":model.predict(features_test)})\n",
        "df = pd.DataFrame({\"actual value \":y_test, \"predicted \":model.predict(features_test)})\n",
        "\n",
        "print(df)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     actual value  predicted \n",
            "400           spam       spam\n",
            "401            ham        ham\n",
            "402            ham        ham\n",
            "403            ham        ham\n",
            "404            ham        ham\n",
            "...            ...        ...\n",
            "5567          spam       spam\n",
            "5568           ham        ham\n",
            "5569           ham        ham\n",
            "5570           ham        ham\n",
            "5571           ham        ham\n",
            "\n",
            "[5172 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFVWQ4MoBu8_"
      },
      "source": [
        "**It seems we are getting a decent accuracy, but can we do any better?**\n",
        "\n",
        "sklearn comes with a class GridSearchCV which helps us find better parameters of our model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5J8pVrpBwwp"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4J31-SbCNMk"
      },
      "source": [
        "Lets list out all our parameters we can tune for our svm model. Parameters are key to machine learning algorithms. In this case, a parameter is a function argument that could have one of a range of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5eLBUqyCPRZ"
      },
      "source": [
        "tuned_parameters = {'kernel': ['rbf','linear'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5cbUuLOCcmk"
      },
      "source": [
        "We will now create the model this time with Grid Search instead and give our parameters that we want to optimize. Grid search is is a trial and error method and since it involves alot of trial and error, our model.fit will take more time to execute. Once we find our best parameters we can print them on our screen so we dont have to do this every time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXff6WCrCrnb",
        "outputId": "f3c02b56-08e8-4a4b-968e-2757f29780af"
      },
      "source": [
        "model = GridSearchCV(svm.SVC(), tuned_parameters)\n",
        "\n",
        "model.fit(features,y_train)\n",
        "print(model.best_params_)\n",
        "\n",
        "#Test Accuracy\n",
        "print(model.score(cv.transform(x_test),y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
            "0.9520494972931168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r02_UFxJtNMF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6pccBodC9eI"
      },
      "source": [
        "Awesome!!! with the new parameters the performance of our model has now improved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzqS_yvpDExc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}